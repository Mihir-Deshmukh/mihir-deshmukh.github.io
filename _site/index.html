<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Mihir Pradeep Deshmukh | WPI</title>

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Personal homepage.">
    
    <meta name="keywords" content="mihir deshmukh">
    
    
    <link rel="canonical" href="https://mihir-deshmukh.github.io/"/>
    

    <link rel="icon" media="(prefers-color-scheme:dark)" href="./assets/img/mihir-deshmukh.png" type="image/png" />
    <link rel="icon" media="(prefers-color-scheme:light)" href="./assets/img/mihir-deshmukh.png" type="image/png" />
    <script src="./assets/js/favicon-switcher.js" type="application/javascript"></script>

    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous>
    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin=anonymous>

    
    <link rel="stylesheet" href="./assets/css/font.css">
    
    
    <link rel="stylesheet" href="./assets/css/style-no-dark-mode.css">
    <link rel="stylesheet" href="./assets/css/publications-no-dark-mode.css">
    

  </head>
  <body>
 
  
    <div class="wrapper">
      <header>
        
        
        <a class="image avatar"><img src="./assets/img/mihir-deshmukh.png" alt="avatar" /></a>
        

        <h1>Mihir Pradeep Deshmukh</h1>

        
        <position style="font-size:1.10rem;">MS Student</position>
        <br>
        
        
        <a href="" rel="noopener"><autocolor>WPI</autocolor></a>
        <br>
        
        
        <email>mpdeshmukh@wpi.edu</email>
        

        <br>
        <br>
        <div class="social-icons">
        

        
        <a style="margin: 0 5px 0 0" href="assets/files/MihirPradeep_Deshmukh_resume.pdf">
          <i class="ai ai-cv" style="font-size:1.3rem;"></i>
        </a>
        

        
        <a style="margin: 0 5px 0 0" href="https://github.com/Mihir-Deshmukh">
          <i class="fab fa-github"></i>
        </a>
        

        
        <a style="margin: 0 5px 0 0" href="https://www.linkedin.com/in/mihir-deshmukh-v15/">
          <i class="fab fa-linkedin"></i>
        </a>
        

        
        <a style="margin: 0 0 0 0" href="mailto:mpdeshmukh@wpi.edu">
          <i class="fa fa-envelope"></i>
        </a>
        
        </div>
        <br>

      </header>
     
      <section>
        <div id="top-bar">
          <a href="#aboutme">About Me</a>
          <a href="#experience">Experience</a>
          <a href="#projects">Projects</a>
          <a href="#publications">Publications</a>
      </div>
      
      <p>I am a student at Worcester Polytechnic Institute(WPI) pursuing Robotics Engineering.
I am interested in the domain of Robotics, specifically Perception, Computer Vision and deep learning in the field of manipulation and mobile robots. I am currently working on vision transformers and grasp generation.</p>

<p><em>I am currently seeking full time opportunities from Summer’25</em></p>

<h2 id="academic-background">Academic Background</h2>

<ul>
  <li><strong>Aug 2023 - May. 2025:</strong> M.S. in Robotics Engineering, Worcester Polytechnic Institute (WPI)</li>
  <li><strong>Aug 2018 - May. 2022:</strong> BTech in Electronics and Telecommunication Engineering<br />
                          Minor in Computer Engineering,<br />
                          College of Engineering, Pune (COEP)</li>
</ul>

<h2 id="research-interests">Research Interests</h2>

<ul>
  <li><strong>Computer Vision:</strong> Image segmentation, monocular depth estimation, object detection</li>
  <li><strong>Deep Learning:</strong> CNNs, Transformers, transfer learning</li>
  <li><strong>Robotics:</strong> Manipulation, grasp generation and perception</li>
</ul>

<!-- ## News

- **[Feb. 2020]** Our paper about incremental learning is accepted to CVPR 2020.
- **[Feb. 2020]** We will host the ACM Multimedia Asia 2020 conference in Singapore!
- **[Sept. 2019]** Our paper about few-shot learning is accepted to NeurIPS 2019.
- **[Mar. 2019]** Our paper about few-shot learning is accepted to CVPR 2019. -->

<h2 id="experience">Experience</h2>

<h4 style="margin:0 10px 0;">Magna Electronics - Software Algorithm Intern</h4>
<ul style="margin:0 0 5px;">
  <li><a><autocolor>Performed Lidar–Camera extrinsic calibration to project Lidar-generated 3D bounding boxes into BEV space, enabling ground truth comparison for monocular camera-based object detection.</autocolor></a></li>
  <li><a><autocolor>Processed CAN bus data to extract GNSS information for HD map queries, enabling real-time location spoofing, lane profile reconstruction, and hardware-independent debugging environment.</autocolor></a></li>
  <li><a><autocolor>Benchmarked Autoware's planner in Carla simulation and contributed to the system design of landmark-based localization.</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Bajaj Finserv - Software Engineer</h4>
<ul style="margin:0 0 5px;">
  <li><a><autocolor>Leveraged .Net Core for Web API creation and Ado.Net for database integration as a member of the Collections Portal Team.</autocolor></a></li>
  <li><a><autocolor>Developed front-end applications in Angular.</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Mitacs Globalink Research Internship (McMaster University) - Research Intern</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Worked under Dr. Gary Bone on the project ”Collaborative Robot Arm Software Development”.</autocolor></a></li>
  <li><a><autocolor>Applied concepts of Ransac segmentation, clustering, and Transforms in Webots and MATLAB. Simulated PR2 for collaboratively
picking objects by processing the point cloud.</autocolor></a></li>
  <!-- <li><a href="https://www.springer.com/journal/11263"><autocolor>International Journal of Computer Vision (IJCV)</autocolor></a></li> -->
</ul>

<h4 style="margin:0 10px 0;">Binary Robotics - Project Intern</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Calibrated cameras using OpenCV to enhance the auto-pick and place mechanism of a gantry system.</autocolor></a></li>
  <li><a><autocolor>Designed an electronic architecture for a 5 axis Gantry system equipped with hybrid servos.</autocolor></a></li>
  <!-- <li><a href="https://www.springer.com/journal/11263"><autocolor>International Journal of Computer Vision (IJCV)</autocolor></a></li> -->
</ul>

<h4 style="margin:0 10px 0;">Robotics and Automation Lab, COEP - Undergraduate Researcher</h4>

<ul style="margin:0 0 20px;">
  <li><a><autocolor>Handled the programming, circuit &amp; PCB designing, perception, and sensor fusion for Omni-wheeled robots as well as research
projects.</autocolor></a></li>
  <li><a><autocolor>Participated in ABU Robocon 2020 and 2021 and worked from ideation to prototyping the robots.</autocolor></a></li>
  <!-- <li><a href="https://www.springer.com/journal/11263"><autocolor>International Journal of Computer Vision (IJCV)</autocolor></a></li> -->
</ul>

<h2 id="projects">Projects</h2>

<h4 style="margin:0 10px 0;">Dexterous Picking Manipulation.</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Directed Research, Advisor - Dr. Berk Calli</autocolor></a></li>
  <li><a><autocolor>Working on identifying grasp candidates for diverse object interactions like sliding and pushing in vertical and horizontal orientations.</autocolor></a></li>
  <li><a><autocolor>Generated simulation data and subsequently concentrated on developing and training models using this data, focusing on transitioning them into real-world applications.</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Structure from motion(SfM) &amp; NeRF</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Applied the chirality condition to ensure the geometric validity of triangulated points for accurate 3D reconstruction.</autocolor></a></li>
  <li><a><autocolor>Enhanced scene depth and detail by integrating additional views through Perspective-n-Points (PnP), followed by Bundle Adjustment for optimal alignment and precision of 3D points.  </autocolor></a></li>
  <li><a><autocolor> Implemented Neural Radiance Fields (NeRF) to synthesize novel views of scenes from a sparse set of input images, leveraging differentiable volume rendering for photorealistic image generation. </autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Deep Learning based Robotic Grasping of unknown objects.</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Developed a pipeline to optimally Grasp objects of variable shape, size, and orientation using vision capabilities.</autocolor></a></li>
  <li><a><autocolor>Applied VGG16 and ResNet50 architectures through Transfer Learning in PyTorch. Adapted this to a custom 3D-printed 5-DoF
robotic arm with MoveIt and the KinectV2 depth camera.</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Visual Slam and Object Recognition using Kinect v2 &amp; ROS</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Implemented RTAB map in gazebo simulator and tested the same using Kinect V2.</autocolor></a></li>
  <li><a><autocolor>Employed the YOLO v3 framework for real-time object detection in tandem with map generation.</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">AutoCalib</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Implemented Zhang's camera calibration method, utilizing non-linear optimization for estimating intrinsic \&amp; distortion parameters.</autocolor></a></li>
  <li><a><autocolor>Implemented distortion model including radial distortion, with parameters estimated through iterative optimization.</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Metalimbs</h4>

<ul style="margin:0 0 5px;">
  <li><a><autocolor>Simulated an anthropomorphic robotic arm with six DOF using human foot movements, integrating leg position tracking via an
IMU and flex sensor-actuated gripping.</autocolor></a></li>
  <li><a><autocolor>Utilized MoveIt for inverse kinematics and trajectory planning.</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Rubik’s Cube Solver.</h4>

<ul style="margin:0 0 20px;">
  <li><a><autocolor>Designed an automated system to solve a Rubik’s Cube, utilizing a camera for input and six stepper motors to actuate each face,
powered by an STM32 microcontroller.</autocolor></a></li>
  <li><a><autocolor>Developed and optimized a color detection and cube-solving algorithm using OpenCV, with a focus on contour analysis.</autocolor></a></li>
</ul>

<h2 id="publications" style="margin: 2px 0px -15px;">Publications</h2>

<div class="publications">
<ol class="bibliography">



<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
     
    <img src="./assets/img/Grasping.png" class="teaser img-fluid z-depth-1" style="width=100;height=40%" />
    
     
    <abbr class="badge">INDICON</abbr>
    
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10040180">Deep Learning based end-to-end Grasping Pipeline on a lowcost 5-DOF Robotic arm</a></div>
      <div class="author">P. Junare,  <strong>M. Deshmukh</strong>, M. Kulkarni and P. Bartakke</div>
      <div class="periodical"><em>IEEE 19th India Council International Conference <strong>(INDICON)</strong>, 2022.</em>
      </div>
    <div class="links">
       
      <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10040180" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      
       
      <a href="https://github.com/Mihir-Deshmukh/Robotic-Grasping" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      
      
      
      
      
    </div>
  </div>
</div>
</li>

<br />



<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
     
    <img src="./assets/img/perception.png" class="teaser img-fluid z-depth-1" style="width=100;height=40%" />
    
     
    <abbr class="badge">ICCCA</abbr>
    
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9666426">Visual SLAM Combined with Object Detection for Autonomous Indoor Navigation Using Kinect V2 and ROS</a></div>
      <div class="author">M. Kulkarni, P. Junare, <strong>M. Deshmukh</strong> and P. P. Rege</div>
      <div class="periodical"><em>IEEE 6th International Conference on Computing,Communication and Automation <strong>(ICCCA)</strong>, 2021.</em>
      </div>
    <div class="links">
       
      <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9666426" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      
      
      
      
      
      
    </div>
  </div>
</div>
</li>

<br />



</ol>
</div>



      <br>

      

      </section>
      <footer>
        
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-111540567-4', 'auto');
      ga('send', 'pageview');
    </script>
    
    <script>
      document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener('click', function (e) {
          e.preventDefault();
          document.querySelector(this.getAttribute('href')).scrollIntoView({
            behavior: 'smooth'
          });
        });
      });
    </script>
    <script>
      document.querySelectorAll('#top-bar a').forEach(link => {
        link.addEventListener('click', function() {
          this.blur(); // Removes focus from the link after clicking
        });
      });
    </script>
    
  </body>
</html>
